---
title: Organisaties kunnen bewijzen dat zij persoonsgegevens op de juiste manier verwerken - Algoritmekader 2.2
url: https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/avg-06-verantwoordingsplicht-rechtmatigheid/index.html
scraped_at: 2025-06-11T13:48:08.724615
---

# Organisaties kunnen bewijzen dat zij persoonsgegevens op de juiste manier verwerken - Algoritmekader 2.2

Source: https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/avg-06-verantwoordingsplicht-rechtmatigheid/index.html

---

[ ![Home Algoritmekader](../../../assets/logo.svg) ](../../.. "Algoritmekader 2.2") Algoritmekader 2.2

[ GitHub  ](https://github.com/MinBZK/Algoritmekader "Ga naar repository")

  * [ Soorten algoritmes en AI  ](../../../soorten-algoritmes-en-ai/)
  * [ Onderwerpen  ](../../../onderwerpen/)
  * [ Levenscyclus  ](../../../levenscyclus/)
  * [ Rollen  ](../../../rollen/)
  * [ Voldoen aan wetten en regels  ](../../)

Inhoudsopgave

  * Vereiste
  * Toelichting
  * Bronnen
  * Van toepassing op
  * Risico
  * Maatregelen

  1. [ Voldoen aan wetten en regels  ](../../)
  2. [ Vereisten  ](../)

# Organisaties kunnen bewijzen dat zij persoonsgegevens op de juiste manier verwerken

[]( "Vereiste ID")avg-06[](../../../levenscyclus/ "Levencyclus")[Ontwerp](../../../levenscyclus/ontwerp/)[](../../../levenscyclus/ "Levencyclus")[Dataverkenning en datapreparatie](../../../levenscyclus/dataverkenning-en-datapreparatie/)[](../../../rollen/ "Rollen")[Jurist](../../../rollen/jurist/)[](../../../onderwerpen/ "Onderwerp")[Governance](../../../onderwerpen/governance/)[](../../../onderwerpen/ "Onderwerp")[Privacy en gegevensbescherming](../../../onderwerpen/privacy-en-gegevensbescherming/)

## Vereiste

Organisaties kunnen bewijzen dat zij persoonsgegevens op de juiste manier verwerken.

## Toelichting

De verantwoordelijken moeten bij de verwerking van persoonsgegevens door algoritmes kunnen aantonen dat de verwerkingen rechtmatig plaatsvinden. Dit betekent concreet dat de volgende punten aangetoond kunnen worden:

  * Rechtmatigheid, behoorlijkheid en transparantie
  * Doelbinding
  * Minimale gegevensverwerking
  * Juistheid
  * Opslagbeperking
  * Integriteit en vertrouwelijkheid

Een aandachtpunt daarbij is dat de rechtmatigheid van de verwerking ten opzichte van andere gerelateerde wetgeving zoals de AI Act en de Algemene wet gelijke behandeling ook moeten kunnen worden aangetoond voor zover de rechtmatigheid van de verwerking onder de AVG daarvan afhankelijk is.

Bij het verwerken van persoonsgegevens voor algoritmes moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn.

De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht.

## Bronnen

  * [Artikel 5 lid 2 Algemene Verordening Gegevensbescherming](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=CELEX:32016R0679#d1e1802-1-1)
  * [Artikel 24 Algemene Verordening Gegevensbescherming](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=CELEX:32016R0679#d1e3035-1-1)
  * [Artikel 26 Algemene Verordening Gegevensbescherming](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=CELEX:32016R0679#d1e3075-1-1)
  * [Artikel 27 Algemene Verordening Gegevensbescherming](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=CELEX:32016R0679#d1e3095-1-1)
  * [Artikel 29 Algemene Verordening Gegevensbescherming](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=CELEX:32016R0679#d1e3247-1-1)
  * [Verantwoordingsplicht](https://www.autoriteitpersoonsgegevens.nl/themas/basis-avg/avg-algemeen/verantwoordingsplicht)

## Van toepassing op

Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.

## Risico

Het niet naleven van deze norm moet worden gekwalificeerd als een onrechtmatigheid, niet als een risico voor de rechten en vrijheden van betrokkenen onder de AVG. Maar het niet voldoen aan artikel 5 betekent in de praktijk vaak wel dat er onvoldoende zicht is op risico's voor de rechten en vrijheden van betrokkenen of dat er te grote risico's worden genomen. Deze gevolgen zijn echter indirect een gevolg van het niet naleven van artikel 5 AVG. Het moeten voldoen aan het aantoonbaarheidsvereiste kan wel risico's hebben voor de organisatie die een algortime inzet. Enkele risico's zijn:

  * Aantoonbaarheidsvereisten vragen in de praktijk veel documentatie. Deze documentatie kan via de Woo opgevraagd worden. Het ontbreken van documentatie kan door externen vaak relatief makkelijk in verband worden gebracht met een overtreding van deze vereisten.
  * Algoritmes die van nature slecht inzichtelijk en uitlegbaar zijn (zoals deep-learning) hebben een zeer hoge drempel om aan deze vereiste te voldoen. Aantonen van rechtmatigheid is voor een belangrijk deel afhankelijk van inzicht in de werking van het algoritme. De inzet van een algortime kan dus mogelijk tegengehouden worden door deze vereisten.
  * Bij leveranciers die niet of gedeeltelijke transparant zijn over hun product of dienstverlening ontstaat een vergelijkbaar risico. Waar de Woo uitzonderingen heeft voor bedrijfsgeheimen heeft de AVG daar maar beperkte ruimte voor. Het is dus mogelijk dat leveranciers terughoudend zullen zijn met het delen van informatie die onder de AVG ook aan betrokkenen gecommuniceerd moeten worden.
  * Samenwerkingsverbanden en externe leveranciers kunnen niet als argumenten worden gebruikt om de aantoonbaarheidsvereisten op af te schuiven. Onafhankelijk van de onderlinge afspraken daarover hebben alle verwerkingsverantwoordelijken de verplichting om aan deze vereisten te kunnen voldoen.

## Maatregelen

id| Maatregelen
---|---
[owp-01](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/index.html)| [Beschrijf de rollen en verantwoordelijkheden voor het ontwikkelen en gebruiken van algoritmes](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/index.html)
[owp-15](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-15-bespreek-vereisten-met-aanbieders/index.html)| [Bespreek de vereisten die gelden voor een verantwoorde inzet van algoritmes met aanbieders](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-15-bespreek-vereisten-met-aanbieders/index.html)
[owp-16](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-16-vereisten-onderdeel-algemene-inkoopvoorwaarden-en-contractovereenkomst/index.html)| [Maak vereisten voor algoritmes onderdeel van algemene inkoopvoorwaarden en de contractovereenkomst](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-16-vereisten-onderdeel-algemene-inkoopvoorwaarden-en-contractovereenkomst/index.html)
[owp-21](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-21-ruimte-voor-samenwerking-met-aanbieder/index.html)| [Creëer ruimte om met een aanbieder samen te gaan werken om specifieke vereisten te realiseren](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-21-ruimte-voor-samenwerking-met-aanbieder/index.html)
[owp-23](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-23-uitvoeren-audit-voor-naleving-vereisten/index.html)| [Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-23-uitvoeren-audit-voor-naleving-vereisten/index.html)
[owp-27](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-27-maak-vereisten-onderdeel-van-programma-van-eisen/index.html)| [Maak vereisten onderdeel van het programma van eisen bij een aanbesteding](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-27-maak-vereisten-onderdeel-van-programma-van-eisen/index.html)
28 februari 2025 4 juli 2024
  *AI-modellen voor algemene doeleinden: Een AI-model, ook wanneer het is getraind met een grote hoeveelheid data met behulp van self-supervision op grote schaal, dat een aanzienlijk algemeen karakter vertoont en in staat is op competente wijze een breed scala aan verschillende taken uit te voeren, ongeacht de wijze waarop het model in de handel wordt gebracht, en dat kan worden geïntegreerd in een verscheidenheid aan systemen verder in de AI-waardeketen of toepassingen verder in de AI-waardeketen, met uitzondering van AI-modellen die worden gebruikt voor onderzoek, ontwikkeling of prototypingactiviteiten alvorens zij in de handel worden gebracht.
  *AI-geletterdheid: vaardigheden, kennis en begrip die aanbieders, gebruiksverantwoordelijken en betrokken personen, rekening houdend met hun respectieve rechten en plichten in het kader van de de AI-verordening, in staat stellen met kennis van zaken AI-systemen in te zetten en zich bewuster te worden van de kansen en risico’s van AI en de mogelijke schade die zij kan veroorzaken
  *AI-model voor algemene doeleinden: Een AI-model, ook wanneer het is getraind met een grote hoeveelheid data met behulp van self-supervision op grote schaal, dat een aanzienlijk algemeen karakter vertoont en in staat is op competente wijze een breed scala aan verschillende taken uit te voeren, ongeacht de wijze waarop het model in de handel wordt gebracht, en dat kan worden geïntegreerd in een verscheidenheid aan systemen verder in de AI-waardeketen of toepassingen verder in de AI-waardeketen, met uitzondering van AI-modellen die worden gebruikt voor onderzoek, ontwikkeling of prototypingactiviteiten alvorens zij in de handel worden gebracht.
  *biometrische gegevens: persoonsgegevens die het resultaat zijn van een specifieke technische verwerking met betrekking tot de fysieke, fysiologische of gedragsgerelateerde kenmerken van een natuurlijk persoon, zoals gezichtsafbeeldingen of vingerafdrukgegevens
  *AI-systeem voor algemene doeleinden: Een AI-systeem dat is gebaseerd op een AI- model voor algemene doeleinden en dat verschillende doeleinden kan dienen, zowel voor direct gebruik als voor integratie in andere AI-systemen
  *systeemrisico: een risico dat specifiek is voor de capaciteiten met een grote impact van AI-modellen voor algemene doeleinden, die aanzienlijke gevolgen hebben voor de markt van de Unie vanwege hun bereik, of vanwege feitelijke of redelijkerwijs te voorziene negatieve gevolgen voor de gezondheid, de veiligheid, de openbare veiligheid, de grondrechten of de samenleving als geheel, en dat op grote schaal in de hele waardeketen kan worden verspreid
  *AI-bureau: De taak van de Commissie waarbij zij bijdraagt aan de uitvoering van, de monitoring van en het toezicht op AI-systemen en AI-modellen voor algemene doeleinden, en AI-governance, als bepaald in het besluit van de Commissie van 24 januari 2024; verwijzingen in deze verordening naar het AI-bureau worden begrepen als verwijzingen naar de Commissie
  *aanbieder: Een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat een AI-systeem of een AI-model voor algemene doeleinden ontwikkelt of laat ontwikkelen en dat systeem of model in de handel brengt of het AI-systeem in gebruik stelt onder de eigen naam of merk, al dan niet tegen betaling.
  *kritieke infrastructuur: kritieke infrastructuur zoals gedefinieerd in artikel 2, punt 4, van Richtlijn (EU) 2022/2557
  *redelijkerwijs te voorzien misbruik: Het gebruik van een AI-systeem op een wijze die niet in overeenstemming is met het beoogde doel, maar die kan voortvloeien uit redelijkerwijs te voorzien menselijk gedrag of redelijkerwijs te voorziene interactie met andere systemen, waaronder andere AI-systemen
  *gebruiksinstructies: de door de aanbieder verstrekte informatie om de gebruiksverantwoordelijke te informeren over met name het beoogde doel en juiste gebruik van een AI-systeem
  *testdata: data die worden gebruikt voor het verrichten van een onafhankelijke evaluatie van het AI-systeem om de verwachte prestaties van dat systeem te bevestigen voordat het in de handel wordt gebracht of in gebruik wordt gesteld
  *in de handel brengen: Het voor het eerst in de Unie op de markt aanbieden van een AI-systeem of een AI-model voor algemene doeleinden
  *inputdata: data die in een AI-systeem worden ingevoerd of direct door een AI-systeem worden verworven en op basis waarvan het systeem een output genereert
  *gebruiksverantwoordelijke: Een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat een AI-systeem onder eigen verantwoordelijkheid gebruikt, tenzij het AI-systeem wordt gebruikt in het kader van een persoonlijke niet- beroepsactiviteit.
  *biometrische identificatie: de geautomatiseerde herkenning van fysieke, fysiologische, gedragsgerelateerde of psychologische menselijke kenmerken om de identiteit van een natuurlijk persoon vast te stellen door biometrische gegevens van die persoon te vergelijken met in een databank opgeslagen biometrische gegevens van personen
  *in gebruik stellen: De directe levering van een AI-systeem door de aanbieder aan de gebruiksverantwoordelijke voor het eerste gebruik of voor eigen gebruik in de Unie voor het beoogde doel
  *systeem voor monitoring na het in de handel brengen: alle door aanbieders van AI-systemen verrichte activiteiten voor het verzamelen en evalueren van ervaringen met door hen in de handel gebrachte of in gebruik gestelde AI-systemen, teneinde te kunnen vaststellen of er onmiddellijk corrigerende dan wel preventieve maatregelen nodig zijn
  *conformiteitsbeoordeling: Het proces waarbij de naleving wordt aangetoond van de voorschriften van hoofdstuk III, afdeling 2 van de AI-Verordening in verband met een AI-systeem met een hoog risico
  *veiligheidscomponent: Een component van een product of systeem die een veiligheidsfunctie voor dat product of systeem vervult of waarvan het falen of gebrekkig functioneren de gezondheid en veiligheid van personen of eigendom in gevaar brengt
  *markttoezichtautoriteit: de nationale autoriteit die de activiteiten verricht en maatregelen neemt als bedoeld in Verordening (EU) 2019/1020
  *gemachtigde: een natuurlijke of rechtspersoon die zich bevindt of gevestigd is in de Unie die een schriftelijke machtiging heeft gekregen en aanvaard van een aanbieder van een AI-systeem of een AI-model voor algemene doeleinden om namens die aanbieder de verplichtingen en procedures van deze verordening respectievelijk na te komen en uit te voeren;
  *CE-markering: Een markering waarmee een aanbieder aangeeft dat een AI-systeem in overeenstemming is met de voorschriften van hoofdstuk III, afdeling 2, en andere toepasselijke harmonisatiewetgeving van de Unie, die in het aanbrengen ervan voorzien
  *distributeur: Een andere natuurlijke persoon of rechtspersoon in de toeleveringsketen dan de aanbieder of de importeur, die een AI-systeem in de Unie op de markt aanbiedt
  *importeur: Een natuurlijke of rechtspersoon die zich bevindt of gevestigd is in de Unie die een AI-systeem in de handel brengt dat de naam of merknaam van een in een derde land gevestigde natuurlijke of rechtspersoon draagt
  *gevoelige operationele gegevens: operationele gegevens met betrekking tot activiteiten op het gebied van preventie, opsporing, onderzoek of vervolging van strafbare feiten waarvan de openbaarmaking de integriteit van strafprocedures in het gedrang zou kunnen brengen
  *deepfake: door AI gegenereerd of gemanipuleerd beeld-, audio- of videomateriaal dat een gelijkenis vertoont met bestaande personen, voorwerpen, plaatsen, entiteiten of gebeurtenissen, en door een persoon ten onrechte voor authentiek of waarheidsgetrouw zou worden aangezien
  *capaciteiten met een grote impact: capaciteiten die overeenkomen met of groter zijn dan de capaciteiten die worden opgetekend bij de meest geavanceerde AI-modellen voor algemene doeleinden.
  *testen onder reële omstandigheden: het tijdelijk testen van een AI-systeem voor zijn beoogde doel onder reële omstandigheden buiten een laboratorium of anderszins gesimuleerde omgeving teneinde betrouwbare en robuuste gegevens te verkrijgen, en te beoordelen en te verifiëren of het AI-systeem overeenstemt met de voorschriften van de AI-verordening en het wordt niet aangemerkt als het in de handel brengen of in gebruik stellen van het AI-systeem in de zin van de AI-verordening, mits aan alle in artikel 57 of 60 vastgestelde voorwaarden is voldaan
  *geïnformeerde toestemming: de vrijelijk gegeven, specifieke, ondubbelzinnige en vrijwillige uiting door een proefpersoon van zijn of haar bereidheid deel te nemen aan een bepaalde test onder reële omstandigheden, na geïnformeerd te zijn over alle aspecten van de test die van belang zijn voor zijn of haar beslissing om deel te nemen
  *auteursrecht: Het auteursrecht is het uitsluitend recht van den maker van een werk van letterkunde, wetenschap of kunst, of van diens rechtverkrijgenden, om dit openbaar te maken en te verveelvoudigen, behoudens de beperkingen, bij de wet gesteld.
  *trainingsdata: data die worden gebruikt voor het trainen van een AI-systeem door de leerbare parameters hiervan aan te passen
  *norm: een norm is een vrijwillige afspraak tussen partijen over een product, dienst of proces. Normen zijn geen wetten, maar ’best practices’. Iedereen kan - op vrijwillige basis - hier zijn voordeel mee doen. In zakelijke overeenkomsten hebben normen een belangrijke functie. Ze bieden marktpartijen duidelijkheid over en vertrouwen in producten, diensten of organisaties en dagen de maatschappij uit te innoveren. NEN-normen worden ontwikkeld door inhoudsexperts en specialisten op het gebied van normontwikkeling.
