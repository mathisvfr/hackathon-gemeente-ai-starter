---
title: Assessment List for Trustworthy Artificial Intelligence (ALTAI) - Algoritmekader 2.2
url: https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/hulpmiddelen/ALTAI/index.html
scraped_at: 2025-06-12T10:32:32.666596
---

# Assessment List for Trustworthy Artificial Intelligence (ALTAI) - Algoritmekader 2.2

Source: https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/hulpmiddelen/ALTAI/index.html

---

[ ![Home Algoritmekader](../../../assets/logo.svg) ](../../.. "Algoritmekader 2.2") Algoritmekader 2.2

[ GitHub  ](https://github.com/MinBZK/Algoritmekader "Ga naar repository")

  * [ Soorten algoritmes en AI  ](../../../soorten-algoritmes-en-ai/)
  * [ Onderwerpen  ](../../../onderwerpen/)
  * [ Levenscyclus  ](../../../levenscyclus/)
  * [ Rollen  ](../../../rollen/)
  * [ Voldoen aan wetten en regels  ](../../)

Inhoudsopgave

  * Hulpmiddel
  * Relevantie
  * Auteur
  * Bijbehorende vereisten
  * Bijbehorende maatregelen

  1. [ Voldoen aan wetten en regels  ](../../)
  2. [ Hulpmiddelen  ](../)

# Assessment List for Trustworthy Artificial Intelligence (ALTAI)

[](../../../levenscyclus/ "Levencyclus")[Ontwerp](../../../levenscyclus/ontwerp/)[](../../../levenscyclus/ "Levencyclus")[Ontwikkelen](../../../levenscyclus/ontwikkelen/)[](../../../rollen/ "Rollen")[Jurist](../../../rollen/jurist/)[](../../../rollen/ "Rollen")[Ontwikkelaar](../../../rollen/ontwikkelaar/)[](../../../rollen/ "Rollen")[Projectleider](../../../rollen/projectleider/)[](../../../rollen/ "Rollen")[Beleid en advies](../../../rollen/beleid-en-advies/)[](../../../onderwerpen/ "Onderwerp")[Privacy en gegevensbescherming](../../../onderwerpen/privacy-en-gegevensbescherming/)[](../../../onderwerpen/ "Onderwerp")[Duurzaamheid](../../../onderwerpen/duurzaamheid/)[](../../../onderwerpen/ "Onderwerp")[Fundamentele rechten](../../../onderwerpen/fundamentele-rechten/)[](../../../onderwerpen/ "Onderwerp")[Technische robuustheid en veiligheid](../../../onderwerpen/technische-robuustheid-en-veiligheid/)[](../../../onderwerpen/ "Onderwerp")[Transparantie](../../../onderwerpen/transparantie/)[](../../../onderwerpen/ "Onderwerp")[Menselijke controle](../../../onderwerpen/menselijke-controle/)[](../../../onderwerpen/ "Onderwerp")[Data](../../../onderwerpen/data/)

[Direct naar de ALTAI](https://digital-strategy.ec.europa.eu/en/library/assessment-list-trustworthy-artificial-intelligence-altai-self-assessment)

## Hulpmiddel

In 2019 publiceerde de High-Level Expert Group on Artificial Intelligence (AI HLEG), opgericht door de Europese Commissie, de [Ethics Guidelines for Trustworthy Artificial Intelligence](https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai). De ALTAI is een hulpmiddel dat ontwikkelaars en organisaties helpt hun AI-systemen te beoordelen, gebaseerd op deze Ethics Guidelines for Trustworthy Artificial Intelligence. Het helpt te bepalen of het AI-systeem dat wordt ontwikkeld, ingezet, aangeschaft of gebruikt, voldoet aan zeven vereisten van betrouwbare AI:

  * Menselijke tussenkomst en toezicht;
  * Technische robuustheid en veiligheid;
  * Privacy en gegevensbeheer;
  * Transparantie;
  * Diversiteit, non-discriminatie en eerlijkheid;
  * Maatschappelijk en ecologisch welzijn;
  * Verantwoordelijkheid

De ALTAI is bedoeld voor zelfevaluatie. Het hulpmiddel is verankerd in de bescherming van de fundamentele rechten van mensen, de term die in de Europese Unie wordt gebruikt om te verwijzen naar de mensenrechten die zijn vastgelegd in de EU-verdragen, het Handvest van de Grondrechten, en het internationale mensenrechtenrecht.

De ALTAI is bedoeld voor flexibele inzet: organisaties kunnen gebruikmaken van de relevante onderdelen van dit hulpmiddel voor een specifiek AI-systeem of er elementen aan toevoegen die zij passend achten, rekening houdend met de sector waarin zij opereren. Het helpt organisaties te begrijpen wat betrouwbare AI inhoudt, in het bijzonder welke risico's een AI-systeem zou kunnen meebrengen en hoe deze risico's kunnen worden geminimaliseerd terwijl de kansen van AI worden gemaximaliseerd. Organisaties halen het meeste waarde uit de ALTAI door de gestelde vragen uitgebreid te beantwoorden, die zijn bedoeld om zorgvuldige reflectie te stimuleren en passende vervolgacties aan te formuleren, en een organisatiecultuur te bevorderen die zich inzet voor de ontwikkeling van betrouwbare AI-systemen. Het vergroot het bewustzijn van de mogelijke impact van AI op de samenleving, het milieu, consumenten, werknemers en burgers (in het bijzonder kinderen en mensen die tot gemarginaliseerde groepen behoren).

## Relevantie

De ALTAI biedt houvast bij het evalueren van in hoeverre een betreffend AI-systeem voldoet aan de zeven vereisten van betrouwbare AI, zoals geformuleerd door de EU. Deze zeven vereisten en de ALTAI hebben samen de basis gevormd voor de AI-verordening.

## Auteur

De ALTAI is ontwikkeld door de High-Level Expert Group on Artificial Intelligence van de Europese Commissie.

## Bijbehorende vereisten

Vereiste
---
[aia-14 - Hoog-risico-AI-systemen worden pas geleverd of gebruikt na een conformiteitsbeoordelingsprocedure](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-14-conformiteitsbeoordeling/)
[awb-01 - Organisaties die algoritmes gebruiken voor publieke taken nemen besluiten zorgvuldig](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/awb-01-zorgvuldigheidsbeginsel/)

## Bijbehorende maatregelen

Maatregel
---
[pba-03 - Beschrijf waarom een algoritme het probleem moet oplossen](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/)
[owp-07 - Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafweging](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-07-afwegen-grondrechten/)
[imp-03 - Richt de juiste menselijke controle in van het algoritme](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-03-menselijke-tussenkomst/)
6-imp-11-proces-privacyrechten
[mon-02 - Beveilig de software](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/7-mon-02-beveiliging-algoritme/)
[pba-05 - Beschrijf de wettelijke grondslag voor de inzet van het algoritme](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/1-pba-05-wettelijke-grondslag/)
[owp-03 - Beschrijf voor welk doel het algoritme persoonsgegevens gebruikt en waarom dit mag](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-03-doel-verwerken-persoonsgegevens/)
[dat-03 - Geef data zoals persoonsgegevens een bewaartermijn met een vernietigingsprocedure](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/3-dat-03-bewaartermijnen-persoonsgegevens/)
[owp-08 - Maak een lijst van de meest kwetsbare groepen en bescherm hen extra](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-08-kwetsbare-groepen/)
[imp-04 - Publiceer impactvolle algoritmes en hoog-risico AI-systemen in het Algoritmeregister](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-04-publiceren-algoritmeregister/)
[ver-03 - Toets het algoritme op bias en voer een rechtvaardigingstoets uit](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/5-ver-03-biasanalyse/)
[ver-01 - Controleer regelmatig of het algoritme werkt zoals het bedoeld is](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/5-ver-01-functioneren-in-lijn-met-doeleinden/)
[owk-03 - Analyseer de privacy-risico’s en neem maatregelen om deze risico’s laag te houden](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/4-owk-03-privacyrisico/)
[owk-01 - Ontwerp en ontwikkel het algoritme volgens de principes van ‘security by design’](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/4-owk-01-security-by-design/)
6 februari 2025 13 november 2024

Terug naar boven
