---
title: Risico van AI-systemen - Algoritmekader 2.2
url: https://minbzk.github.io/Algoritmekader/soorten-algoritmes-en-ai/risico-van-ai-systemen/
scraped_at: 2025-06-11T13:47:11.291651
---

# Risico van AI-systemen - Algoritmekader 2.2

Source: https://minbzk.github.io/Algoritmekader/soorten-algoritmes-en-ai/risico-van-ai-systemen/

---

[ ![Home Algoritmekader](../../assets/logo.svg) ](../.. "Algoritmekader 2.2") Algoritmekader 2.2

[ GitHub  ](https://github.com/MinBZK/Algoritmekader "Ga naar repository")

  * [ Soorten algoritmes en AI  ](../)

Soorten algoritmes en AI
    * [ Wat is een algoritme?  ](../wat-is-een-algoritme/)
    * Risico van AI-systemen  [ Risico van AI-systemen  ](./) Inhoudsopgave
      * Risico op misleiding
      * Hoog-risico-AI-systeem
        * Gebruik als veiligheidsonderdeel
        * Gebruik voor bepaalde diensten of processen
      * Verboden AI
      * Voldoen aan de AI-verordening
      * Help ons deze pagina te verbeteren
    * [ Impact van algoritmes  ](../impact-van-algoritmes/)
    * [ Generatieve AI  ](../generatieve-ai/)
    * [ Woordenlijst  ](../definities/)
  * [ Onderwerpen  ](../../onderwerpen/)
  * [ Levenscyclus  ](../../levenscyclus/)
  * [ Rollen  ](../../rollen/)
  * [ Voldoen aan wetten en regels  ](../../voldoen-aan-wetten-en-regels/)

Inhoudsopgave

  * Risico op misleiding
  * Hoog-risico-AI-systeem
    * Gebruik als veiligheidsonderdeel
    * Gebruik voor bepaalde diensten of processen
  * Verboden AI
  * Voldoen aan de AI-verordening
  * Help ons deze pagina te verbeteren

# Risico van AI-systemen

Valt je AI-systeem onder een risicogroep uit de Europese AI-verordening, dan gelden speciale regels. Hoe groter het risico voor de samenleving, hoe strenger de regels. Het hangt ervan af waarvoor je het AI-systeem gebruikt.

## Risico op misleiding

In deze risicogroep vallen AI-systemen die je gebruikt voor:

  * **interactie met mensen** , zoals AI-chatbots
  * **genereren van content** , zoals afbeeldingen laten maken door Dall-E

Hiervoor gelden verplichtingen op het gebied van transparantie. Gebruikers mogen niet denken dat zij te maken hebben met echte mensen of originele content.

Zie [AI-verordening, hoofdstuk IV](https://eur-lex.europa.eu/legal-content/NL/TXT/?uri=CELEX:32024R1689#d1e5418-1-1).

## Hoog-risico-AI-systeem

In deze risicogroep vallen AI-systemen die je gebruikt als veiligheidsonderdeel van bepaalde producten, of voor bepaalde diensten of processen.

### Gebruik als veiligheidsonderdeel

'Gebruiken als veiligheidsonderdeel' betekent dat je AI-systeem een belangrijke rol speelt in de veiligheid van een product. En dit product valt onder de harmonisatiewetgeving van de EU, zoals:

  * machines
  * speelgoed
  * liften
  * uitrusting en beveiligingssystemen voor plaatsen met ontploffingsgevaar
  * radioapparatuur
  * drukapparatuur
  * pleziervaartuigen
  * kabelbaaninstallaties
  * gastoestellen
  * medische hulpmiddelen
  * hulpmiddelen voor het testen van menselijk materiaal (in-vitrodiagnostiek)
  * auto-industrie
  * luchtvaartindustrie

Zie [AI-verordening, bijlage I](https://eur-lex.europa.eu/legal-content/NL/TXT/?uri=CELEX:32024R1689#d1e38-124-1).

### Gebruik voor bepaalde diensten of processen

Dit zijn AI-systemen die je gebruikt voor:

  * **Biometrie** , zoals het herkennen of indelen van mensen op basis van hun vingerafdruk, gezicht of andere lichamelijke kenmerken.
  * **Kritieke infrastructuur** , zoals het veilig houden van digitale netwerken en verkeersnetwerken en het leveren van elektriciteit, water, gas en warmte.
  * **Onderwijs en beroepsopleiding** , zoals het bepalen welke studenten je toelaat en het beoordelen van hun prestaties of gedrag.
  * **Werkgelegenheid, personeelsbeheer en toegang tot zelfstandige arbeid** , zoals het werven en selecteren van mensen, besluiten nemen die invloed hebben op hun contract en het beoordelen van hun prestaties of gedrag.
  * **Essentiële particuliere en openbare diensten** , zoals bepalen wie recht heeft op uitkeringen, gezondheidszorg en andere belangrijke diensten en wie noodhulp krijgt van politie, brandweer en ambulance, het beoordelen van iemands financiële situatie, fraude opsporen en het bepalen van risico’s en prijzen voor levensverzekeringen en ziektekostenverzekeringen.
  * **Rechtshandhaving** , zoals iemands kans inschatten om slachtoffer of dader te worden, het gebruik van een leugendetector, het beoordelen van bewijsmateriaal en het opsporen van verdachten.
  * **Migratie, asiel en grenzen** , zoals inschatten wat de kans is dat iemand gevaarlijk of illegaal is, het behandelen van aanvragen en klachten en het herkennen of opsporen van mensen.
  * **Rechtsbedeling en democratische processen** , zoals het uitleggen van de wet aan een rechtbank, gerechtshof of de Hoge Raad, advies geven bij een geschil of het beïnvloeden van de uitslag van een verkiezing.

Zie [AI-verordening, bijlage III](https://eur-lex.europa.eu/legal-content/NL/TXT/?uri=CELEX:32024R1689#d1e38-127-1).

## Verboden AI

Deze risicogroep bestaat uit soorten AI-praktijken die volgens de AI-verordening verboden zijn.

Dit zijn AI-systemen die:

  * misleiden
  * misbruik maken van kwetsbaarheden of gevoelige situaties, zoals het overhalen van mensen met schulden om iets te kopen
  * sociale scores bijhouden voor gedrag van mensen en hen hiervoor straffen
  * beoordelen hoe groot het risico is dat iemand een strafbaar feit pleegt
  * afbeeldingen van gezichten ‘scrapen’ (verzamelen) via internet of bewakingscamera’s en deze opslaan in een databank
  * emoties herkennen van mensen op hun werkplek of op school
  * biometrisch categoriseren: mensen indelen in gevoelige categorieën zoals ras en geloof, op basis van lichamelijke kenmerken zoals huidskleur
  * biometrisch identificeren op afstand voor rechtshandhaving, zoals gezichten herkennen via camera’s op een openbaar plein (hiervoor gelden uitzonderingen in ernstige situaties zoals ontvoeringen en terrorisme)

Zie [AI-verordening, artikel 5](https://eur-lex.europa.eu/legal-content/NL/TXT/?uri=CELEX:32024R1689#d1e2816-1-1).

## Voldoen aan de AI-verordening

Als je AI-systeem onder een risicogroep valt, moet je voldoen aan vereisten uit de [AI-verordening](../../voldoen-aan-wetten-en-regels/ai-verordening/). Bekijk de [tijdlijn met vereisten](../../voldoen-aan-wetten-en-regels/tijdlijn-ai-verordening/) of gebruik de [beslishulp AI-verordening](https://ai-act-decisiontree.apps.digilab.network/).

## Help ons deze pagina te verbeteren

Deel je idee, suggestie of opmerking via [GitHub](https://github.com/MinBZK/Algoritmekader/issues/new/choose) of mail ons via [algoritmes@minbzk.nl](mailto:algoritmes@minbzk.nl).

18 april 2025 18 december 2024

Terug naar boven
  *AI-modellen voor algemene doeleinden: Een AI-model, ook wanneer het is getraind met een grote hoeveelheid data met behulp van self-supervision op grote schaal, dat een aanzienlijk algemeen karakter vertoont en in staat is op competente wijze een breed scala aan verschillende taken uit te voeren, ongeacht de wijze waarop het model in de handel wordt gebracht, en dat kan worden geïntegreerd in een verscheidenheid aan systemen verder in de AI-waardeketen of toepassingen verder in de AI-waardeketen, met uitzondering van AI-modellen die worden gebruikt voor onderzoek, ontwikkeling of prototypingactiviteiten alvorens zij in de handel worden gebracht.
  *AI-geletterdheid: vaardigheden, kennis en begrip die aanbieders, gebruiksverantwoordelijken en betrokken personen, rekening houdend met hun respectieve rechten en plichten in het kader van de de AI-verordening, in staat stellen met kennis van zaken AI-systemen in te zetten en zich bewuster te worden van de kansen en risico’s van AI en de mogelijke schade die zij kan veroorzaken
  *AI-model voor algemene doeleinden: Een AI-model, ook wanneer het is getraind met een grote hoeveelheid data met behulp van self-supervision op grote schaal, dat een aanzienlijk algemeen karakter vertoont en in staat is op competente wijze een breed scala aan verschillende taken uit te voeren, ongeacht de wijze waarop het model in de handel wordt gebracht, en dat kan worden geïntegreerd in een verscheidenheid aan systemen verder in de AI-waardeketen of toepassingen verder in de AI-waardeketen, met uitzondering van AI-modellen die worden gebruikt voor onderzoek, ontwikkeling of prototypingactiviteiten alvorens zij in de handel worden gebracht.
