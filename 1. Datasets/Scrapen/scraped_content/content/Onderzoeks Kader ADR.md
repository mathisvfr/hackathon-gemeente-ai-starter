---
title: Onderzoekskader algoritmes Auditdienst Rijk 2023 - Algoritmekader 2.2
url: https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/hulpmiddelen/onderzoekskader-adr/index.html
scraped_at: 2025-06-12T10:32:44.042378
---

# Onderzoekskader algoritmes Auditdienst Rijk 2023 - Algoritmekader 2.2

Source: https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/hulpmiddelen/onderzoekskader-adr/index.html

---

[ ![Home Algoritmekader](../../../assets/logo.svg) ](../../.. "Algoritmekader 2.2") Algoritmekader 2.2

[ GitHub  ](https://github.com/MinBZK/Algoritmekader "Ga naar repository")

  * [ Soorten algoritmes en AI  ](../../../soorten-algoritmes-en-ai/)
  * [ Onderwerpen  ](../../../onderwerpen/)
  * [ Levenscyclus  ](../../../levenscyclus/)
  * [ Rollen  ](../../../rollen/)
  * [ Voldoen aan wetten en regels  ](../../)

Inhoudsopgave

  * Hulpmiddel
  * Relevantie
  * Auteur
  * Bijbehorende vereisten
  * Bijbehorende maatregelen

  1. [ Voldoen aan wetten en regels  ](../../)
  2. [ Hulpmiddelen  ](../)

# Onderzoekskader algoritmes Auditdienst Rijk 2023

[](../../../levenscyclus/ "Levencyclus")[Ontwerp](../../../levenscyclus/ontwerp/)[](../../../levenscyclus/ "Levencyclus")[Implementatie](../../../levenscyclus/implementatie/)[](../../../levenscyclus/ "Levencyclus")[Monitoring en beheer](../../../levenscyclus/monitoring-en-beheer/)[](../../../rollen/ "Rollen")[Projectleider](../../../rollen/projectleider/)[](../../../rollen/ "Rollen")[Beleid en advies](../../../rollen/beleid-en-advies/)[](../../../onderwerpen/ "Onderwerp")[Governance](../../../onderwerpen/governance/)

[Direct naar Onderzoekskader algoritmes](https://www.auditdienstrijk.nl/kennis-delen/documenten/publicaties/2023/11/7/onderzoekskader-algoritmes-auditdienst-rijk-2023)

## Hulpmiddel

Dit onderzoekskader is een instrument om de beheersing van algoritmes in kaart te brengen. Het geeft inzicht in de risico’s die algoritmes met zich meebrengen en met welke maatregelen deze risico’s beheerst (kunnen) worden.

Het onderzoekskader is in eerste instantie bedoeld als instrument voor auditors om de beheersing en werking van algoritmes binnen overheidsorganisaties te onderzoeken, maar is ook bruikbaar voor andere partijen om inzicht te krijgen in de huidige en/of gewenste beheersing van algoritme(s).

Het kader richt zich op algoritmes die binnen overheidsorganisaties gebruikt worden. Het is ingericht op algoritmes die zelf van voorbeelden leren, zoals machine learning, maar is ook toepasbaar op regelgebaseerde algoritmes. Het kader is ook bruikbaar voor andere organisaties en kan bij verschillende fases van de levenscyclus van een algoritme worden ingezet. Mogelijk zijn niet alle thema’s relevant gezien de context van het algoritme. De opdrachtgever en auditor(s) dienen daarom voorafgaand aan een onderzoek te analyseren en te bepalen welke thema’s en onderwerpen worden onderzocht. Het onderzoekskader is ingedeeld in 4 thema’s:

  * Sturing en Verantwoording
  * Privacy
  * Data en Model
  * Informatiebeveiliging

Ethiek raakt alle thema’s en komt daarom bij elk thema in het kader terug. Elk thema bevat deelgebieden en de risico’s en beheersmaatregelen die daarbij horen (inclusief de bron). Ook deze kunnen weer gerelateerd zijn aan een ander thema. Een apart werkbestand voor auditors is opgesteld wat kan worden gebruikt bij het uitvoeren van een onderzoek. Dit bestand heeft dezelfde opbouw, maar bevat ook invulvelden om als auditor het risico (kans x impact) in te schatten en de bevindingen op te nemen. Daarnaast zijn toelichtingen en voorbeelden van checks en evidence opgenomen per beheersmaatregel.

## Relevantie

Het onderzoekskader is ontwikkeld met behulp van nationale en internationale richtlijnen en kaders, rapporten en instrumenten, zoals de [Ethics guidelines for trustworthy AI](https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai) van de Europese Commissie (EC), [Impact Assessment voor Mensenrechten bij de inzet van Algoritmes (IAMA)](../IAMA/), de ['Richtlijnen voor het toepassen van algoritmen door overheden en publieksvoorlichting over data-analyses' van het ministerie van JenV](https://www.rijksoverheid.nl/documenten/richtlijnen/2021/09/24/richtlijnen-voor-het-toepassen-van-algoritmen-door-overheden-en-publieksvoorlichting-over-data-analyses), het [DPIA](../DPIA/) model Rijksoverheid (gebaseerd op o.a. AVG) en de Guiding Principles Trustworthy AI Investigations van NOREA (beroepsvereniging IT-auditors Nederland). De bron van de betreffende risico’s en beheersmaatregelen is tevens opgenomen.

Dit onderzoekskader is erg overkoepelend (net als het [toetsingskader van de Algemene Rekenkamer](../toetsingskader-algemene-rekenkamer/)). Er zijn dan ook veel maatregelen in het Algoritmekader gebaseerd op maatregelen die in het kader van de ADR staan. [Bekijk alle maatregelen van het Algoritmekader hier](../../maatregelen/).

## Auteur

Het Onderzoekskader Algoritmes is ontwikkeld door de Auditdienst Rijk

## Bijbehorende vereisten

Vereiste
---
[aia-06 - Hoog-risico-AI-systemen zijn voorzien van voldoende technische documentatie](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-06-technische-documentatie/)

## Bijbehorende maatregelen

Geen maatregelen beschikbaar voor dit hulpmiddel.

10 april 2025 13 november 2024

Terug naar boven
  *norm: een norm is een vrijwillige afspraak tussen partijen over een product, dienst of proces. Normen zijn geen wetten, maar ’best practices’. Iedereen kan - op vrijwillige basis - hier zijn voordeel mee doen. In zakelijke overeenkomsten hebben normen een belangrijke functie. Ze bieden marktpartijen duidelijkheid over en vertrouwen in producten, diensten of organisaties en dagen de maatschappij uit te innoveren. NEN-normen worden ontwikkeld door inhoudsexperts en specialisten op het gebied van normontwikkeling.
  *aanbieder: Een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat een AI-systeem of een AI-model voor algemene doeleinden ontwikkelt of laat ontwikkelen en dat systeem of model in de handel brengt of het AI-systeem in gebruik stelt onder de eigen naam of merk, al dan niet tegen betaling.
