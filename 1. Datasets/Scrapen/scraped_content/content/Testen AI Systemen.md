---
title: Hoog-risico-AI-systemen zijn getest - Algoritmekader 2.2
url: https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-38-testen/index.html
scraped_at: 2025-06-11T13:47:58.768563
---

# Hoog-risico-AI-systemen zijn getest - Algoritmekader 2.2

Source: https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-38-testen/index.html

---

[ ![Home Algoritmekader](../../../assets/logo.svg) ](../../.. "Algoritmekader 2.2") Algoritmekader 2.2

[ GitHub  ](https://github.com/MinBZK/Algoritmekader "Ga naar repository")

  * [ Soorten algoritmes en AI  ](../../../soorten-algoritmes-en-ai/)
  * [ Onderwerpen  ](../../../onderwerpen/)
  * [ Levenscyclus  ](../../../levenscyclus/)
  * [ Rollen  ](../../../rollen/)
  * [ Voldoen aan wetten en regels  ](../../)

Inhoudsopgave

  * Vereiste
  * Toelichting
    * Testen van AI-systemen met een hoog risico onder reële omstandigheden buiten AI-testomgevingen
  * Bronnen
  * Van toepassing op
  * Risico
  * Maatregelen

  1. [ Voldoen aan wetten en regels  ](../../)
  2. [ Vereisten  ](../)

# Hoog-risico-AI-systemen zijn getest

[]( "Vereiste ID")aia-38[](../../../levenscyclus/ "Levencyclus")[Ontwerp](../../../levenscyclus/ontwerp/)[](../../../levenscyclus/ "Levencyclus")[Ontwikkelen](../../../levenscyclus/ontwikkelen/)[](../../../levenscyclus/ "Levencyclus")[Monitoring en beheer](../../../levenscyclus/monitoring-en-beheer/)[](../../../levenscyclus/ "Levencyclus")[Verificatie en validatie](../../../levenscyclus/verificatie-en-validatie/)[](../../../rollen/ "Rollen")[Projectleider](../../../rollen/projectleider/)[](../../../rollen/ "Rollen")[Ontwikkelaar](../../../rollen/ontwikkelaar/)[](../../../onderwerpen/ "Onderwerp")[Technische robuustheid en veiligheid](../../../onderwerpen/technische-robuustheid-en-veiligheid/)

## Vereiste

Hoog-risico-AI-systemen zijn getest.

## Toelichting

AI-systemen met een hoog risico worden getest met het oog op het vaststellen van passende en gerichte risicobeheersmaatregelen. De tests zorgen ervoor dat AI-systemen met een hoog risico consistent presteren ten aanzien van het doel ervan en in overeenstemming zijn met de geldende eisen.

Het testen van AI-systemen met een hoog risico vindt, zoals passend, in de loop van het ontwikkelproces plaats en in ieder geval voordat het systeem in de handel wordt gebracht of in gebruik is gesteld.

Er wordt getest aan de hand van vooraf vastgestelde beoordelingsmaatstaven en probabilistische drempels die passend zijn voor het beoogde doel van het AI-systeem met een hoog risico. De procedures voor testen zijn onderdeel van het [kwaliteitsbeheer](../aia-11-systeem-voor-kwaliteitsbeheer/).

Bij het verwerken van persoonsgegevens voor het ontwikkelen, trainen en testen van een AI-systeem in een AI-testomgeving, wordt een volledige en gedetailleerde beschrijving van het testproces en de testresultaten onderdeel van de technische documentatie.

### Testen van AI-systemen met een hoog risico onder reële omstandigheden buiten AI-testomgevingen

AI-systemen met een hoog risico kunnen onder reële omstandigheden buiten AI-testomgevingen voor regelgeving worden getest door aanbieders of potentiële aanbieders van in bijlage III vermelde AI-systemen met een hoog risico in overeenstemming met dit artikel en het in dit artikel bedoelde plan voor tests onder reële omstandigheden, onverminderd de verbodsbepalingen krachtens artikel 5 AI-Verordening.

Aanbieders of potentiële aanbieders kunnen zelf of in samenwerking met een of meer gebruiksverantwoordelijken of potentiële gebruiksverantwoordelijken onder reële omstandigheden tests uitvoeren op in bijlage III bedoelde AI-systemen met een hoog risico op elk moment vóór het in de handel brengen of in gebruik nemen van het AI-systeem.

Aanbieders of potentiële aanbieders mogen alleen testen onder reële omstandigheden als is voldaan aan alle volgende voorwaarden:

a. de aanbieder of potentiële aanbieder heeft een plan voor tests onder reële omstandigheden opgesteld en ingediend bij de markttoezichtautoriteit in de lidstaat waar onder reële omstandigheden moet worden getest;

b. de markttoezichtautoriteit in de lidstaat waar onder reële omstandigheden moet worden getest, heeft het testen onder reële omstandigheden en het plan voor tests onder reële omstandigheden goedgekeurd; indien de markttoezichtautoriteit binnen dertig dagen geen antwoord heeft gegeven, worden het testen onder reële omstandigheden en het plan voor tests onder reële omstandigheden geacht te zijn goedgekeurd; indien het nationale recht niet voorziet in een stilzwijgende goedkeuring, blijft het testen onder reële omstandigheden onderworpen aan een toestemming;

c. de aanbieder of potentiële aanbieder, met uitzondering van aanbieders of potentiële aanbieders van in de punten 1, 6 en 7 van bijlage III bedoelde AI-systemen met een hoog risico op de gebieden rechtshandhaving, migratie, asiel en grenstoezichtsbeheer en AI-systemen met een hoog risico als bedoeld in punt 2 van bijlage III, heeft het testen onder reële omstandigheden geregistreerd overeenkomstig artikel 71, lid 4, met een Uniebreed uniek identificatienummer en de in bijlage IX gespecificeerde informatie; de aanbieder of potentiële aanbieder van in de punten 1, 6 en 7 van bijlage III bedoelde AI-systemen met een hoog risico op de gebieden van rechtshandhaving, migratie, asiel en grenstoezichtsbeheer, heeft het testen onder reële omstandigheden geregistreerd in het beveiligde niet-openbare gedeelte van de EU-databank overeenkomstig artikel 49, lid 4, punt d), met een Uniebreed uniek identificatienummer en de daarin gespecificeerde informatie; de aanbieder of potentiële aanbieder van in punt 2 van bijlage III bedoelde AI-systemen met een hoog risico heeft het testen onder reële omstandigheden geregistreerd overeenkomstig artikel 49, lid 5;

d. de aanbieder of potentiële aanbieder die onder reële omstandigheden test, is in de Unie gevestigd of heeft een in de Unie gevestigde wettelijke vertegenwoordiger aangewezen;

e. gegevens die zijn verzameld en verwerkt met het oog op het testen onder reële omstandigheden mogen alleen aan derde landen worden doorgegeven mits er passende en toepasselijke waarborgen uit hoofde van het Unierecht worden toegepast;

f. het testen onder reële omstandigheden duurt niet langer dan nodig is om de doelstellingen ervan te verwezenlijken en in geen geval langer dan zes maanden, met een mogelijke verlenging van nog eens zes maanden indien de aanbieder of potentiële aanbieder de markttoezichtautoriteit daar vooraf van in kennis stelt, met een uitleg waarom een dergelijke verlenging noodzakelijk is;

g. proefpersonen die onder reële omstandigheden worden getest en die tot kwetsbare groepen behoren vanwege hun leeftijd of handicap, worden naar behoren beschermd;

h. indien een aanbieder of potentiële aanbieder het testen onder reële omstandigheden organiseert in samenwerking met een of meer gebruiksverantwoordelijken of potentiële gebruiksverantwoordelijken, worden zij geïnformeerd over alle aspecten van het testen die relevant zijn voor hun beslissing om deel te nemen, en krijgen zij de relevante gebruiksinstructies van het AI-systeem als bedoeld in artikel 13; de aanbieder of potentiële aanbieder en de gebruiksverantwoordelijke of potentiële gebruiksverantwoordelijke sluiten een overeenkomst waarin hun taken en verantwoordelijkheden worden gespecificeerd teneinde te waarborgen dat de bepalingen voor het testen onder reële omstandigheden uit hoofde van deze verordening en ander toepasselijk Unie- en nationaal recht worden nageleefd;

i. de proefpersonen die onder reële omstandigheden worden getest, hebben geïnformeerde toestemming gegeven overeenkomstig artikel 61, of, in het geval van rechtshandhaving, indien het vragen om geïnformeerde toestemming het testen van het AI-systeem onder reële omstandigheden onmogelijk zou maken, de test zelf en het resultaat van de test onder reële omstandigheden hebben geen negatieve gevolgen voor de proefpersonen en hun persoonsgegevens worden na de uitvoering van test gewist;

j. op het testen onder reële omstandigheden wordt daadwerkelijk toezicht gehouden door de aanbieder of potentiële aanbieder, alsook door gebruiksverantwoordelijken of potentiële gebruiksverantwoordelijken via personen die voldoende zijn gekwalificeerd op het relevante gebied en beschikken over de nodige capaciteiten, opleiding en bevoegdheden om hun taken uit te voeren;

k. de voorspellingen, aanbevelingen of beslissingen van het AI-systeem kunnen daadwerkelijk worden teruggedraaid en genegeerd.

## Bronnen

[Artikel 9(6 en 8) Verordening Artificiële Intelligentie](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3241-1-1)

[Artikel 17(1 sub d) Verordening Artificiële Intelligentie](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3241-1-1)

[Artikel 59(1 sub i) Verordening Artificiële Intelligentie](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3241-1-1)

[Artikel 60 Verordening Artificiële Intelligentie](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3241-1-1)

[Overweging 138 - 141 Verordening Artificiële Intelligentie](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3906-1-1)

## Van toepassing op

Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de [beslishulp](https://ai-act-decisiontree.apps.digilab.network) voor hulp bij wat er in jouw situatie van toepassing is.

[](../../../soorten-algoritmes-en-ai/wat-is-een-algoritme/ "Soort toepassing")[AI-systeem](../../ai-verordening/#ai-systeem)[](../../../soorten-algoritmes-en-ai/wat-is-een-algoritme/ "Soort toepassing")[AI-systeem voor algemene doeleinden](../../ai-verordening/#ai-model-voor-algemene-doeleinden)[](../../ai-verordening/#risicogroepen "Risicogroep")[Hoog risico AI-systeem](../../../soorten-algoritmes-en-ai/risico-van-ai-systemen/#hoog-risico-ai-systeem)[](../../ai-verordening/#rollen-uit-de-ai-verordening "Rol AI-verordening")[Aanbieder](../../ai-verordening/#aanbieder)[](../../../soorten-algoritmes-en-ai/risico-van-ai-systemen/#risico-op-misleiding "Transparantieverplichting AI-verordening")[Geen transparantieverplichting](../../../soorten-algoritmes-en-ai/risico-van-ai-systemen/#risico-op-misleiding)[](../../../soorten-algoritmes-en-ai/risico-van-ai-systemen/#risico-op-misleiding "Transparantieverplichting AI-verordening")[Transparantieverplichting](../../../soorten-algoritmes-en-ai/risico-van-ai-systemen/#risico-op-misleiding)

## Risico

Zonder het testen van een AI-systeem, ontstaat het risico dat het AI-systeem inconsistent gaat presteren ten aanzien van het doel.

## Maatregelen

id| Maatregelen
---|---
19 maart 2025 17 december 2024
  *AI-modellen voor algemene doeleinden: Een AI-model, ook wanneer het is getraind met een grote hoeveelheid data met behulp van self-supervision op grote schaal, dat een aanzienlijk algemeen karakter vertoont en in staat is op competente wijze een breed scala aan verschillende taken uit te voeren, ongeacht de wijze waarop het model in de handel wordt gebracht, en dat kan worden geïntegreerd in een verscheidenheid aan systemen verder in de AI-waardeketen of toepassingen verder in de AI-waardeketen, met uitzondering van AI-modellen die worden gebruikt voor onderzoek, ontwikkeling of prototypingactiviteiten alvorens zij in de handel worden gebracht.
  *AI-geletterdheid: vaardigheden, kennis en begrip die aanbieders, gebruiksverantwoordelijken en betrokken personen, rekening houdend met hun respectieve rechten en plichten in het kader van de de AI-verordening, in staat stellen met kennis van zaken AI-systemen in te zetten en zich bewuster te worden van de kansen en risico’s van AI en de mogelijke schade die zij kan veroorzaken
  *AI-model voor algemene doeleinden: Een AI-model, ook wanneer het is getraind met een grote hoeveelheid data met behulp van self-supervision op grote schaal, dat een aanzienlijk algemeen karakter vertoont en in staat is op competente wijze een breed scala aan verschillende taken uit te voeren, ongeacht de wijze waarop het model in de handel wordt gebracht, en dat kan worden geïntegreerd in een verscheidenheid aan systemen verder in de AI-waardeketen of toepassingen verder in de AI-waardeketen, met uitzondering van AI-modellen die worden gebruikt voor onderzoek, ontwikkeling of prototypingactiviteiten alvorens zij in de handel worden gebracht.
  *biometrische gegevens: persoonsgegevens die het resultaat zijn van een specifieke technische verwerking met betrekking tot de fysieke, fysiologische of gedragsgerelateerde kenmerken van een natuurlijk persoon, zoals gezichtsafbeeldingen of vingerafdrukgegevens
  *AI-systeem voor algemene doeleinden: Een AI-systeem dat is gebaseerd op een AI- model voor algemene doeleinden en dat verschillende doeleinden kan dienen, zowel voor direct gebruik als voor integratie in andere AI-systemen
  *systeemrisico: een risico dat specifiek is voor de capaciteiten met een grote impact van AI-modellen voor algemene doeleinden, die aanzienlijke gevolgen hebben voor de markt van de Unie vanwege hun bereik, of vanwege feitelijke of redelijkerwijs te voorziene negatieve gevolgen voor de gezondheid, de veiligheid, de openbare veiligheid, de grondrechten of de samenleving als geheel, en dat op grote schaal in de hele waardeketen kan worden verspreid
  *AI-bureau: De taak van de Commissie waarbij zij bijdraagt aan de uitvoering van, de monitoring van en het toezicht op AI-systemen en AI-modellen voor algemene doeleinden, en AI-governance, als bepaald in het besluit van de Commissie van 24 januari 2024; verwijzingen in deze verordening naar het AI-bureau worden begrepen als verwijzingen naar de Commissie
  *aanbieder: Een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat een AI-systeem of een AI-model voor algemene doeleinden ontwikkelt of laat ontwikkelen en dat systeem of model in de handel brengt of het AI-systeem in gebruik stelt onder de eigen naam of merk, al dan niet tegen betaling.
  *kritieke infrastructuur: kritieke infrastructuur zoals gedefinieerd in artikel 2, punt 4, van Richtlijn (EU) 2022/2557
  *redelijkerwijs te voorzien misbruik: Het gebruik van een AI-systeem op een wijze die niet in overeenstemming is met het beoogde doel, maar die kan voortvloeien uit redelijkerwijs te voorzien menselijk gedrag of redelijkerwijs te voorziene interactie met andere systemen, waaronder andere AI-systemen
  *gebruiksinstructies: de door de aanbieder verstrekte informatie om de gebruiksverantwoordelijke te informeren over met name het beoogde doel en juiste gebruik van een AI-systeem
  *testdata: data die worden gebruikt voor het verrichten van een onafhankelijke evaluatie van het AI-systeem om de verwachte prestaties van dat systeem te bevestigen voordat het in de handel wordt gebracht of in gebruik wordt gesteld
  *in de handel brengen: Het voor het eerst in de Unie op de markt aanbieden van een AI-systeem of een AI-model voor algemene doeleinden
  *inputdata: data die in een AI-systeem worden ingevoerd of direct door een AI-systeem worden verworven en op basis waarvan het systeem een output genereert
  *gebruiksverantwoordelijke: Een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat een AI-systeem onder eigen verantwoordelijkheid gebruikt, tenzij het AI-systeem wordt gebruikt in het kader van een persoonlijke niet- beroepsactiviteit.
  *biometrische identificatie: de geautomatiseerde herkenning van fysieke, fysiologische, gedragsgerelateerde of psychologische menselijke kenmerken om de identiteit van een natuurlijk persoon vast te stellen door biometrische gegevens van die persoon te vergelijken met in een databank opgeslagen biometrische gegevens van personen
  *in gebruik stellen: De directe levering van een AI-systeem door de aanbieder aan de gebruiksverantwoordelijke voor het eerste gebruik of voor eigen gebruik in de Unie voor het beoogde doel
  *systeem voor monitoring na het in de handel brengen: alle door aanbieders van AI-systemen verrichte activiteiten voor het verzamelen en evalueren van ervaringen met door hen in de handel gebrachte of in gebruik gestelde AI-systemen, teneinde te kunnen vaststellen of er onmiddellijk corrigerende dan wel preventieve maatregelen nodig zijn
  *conformiteitsbeoordeling: Het proces waarbij de naleving wordt aangetoond van de voorschriften van hoofdstuk III, afdeling 2 van de AI-Verordening in verband met een AI-systeem met een hoog risico
  *veiligheidscomponent: Een component van een product of systeem die een veiligheidsfunctie voor dat product of systeem vervult of waarvan het falen of gebrekkig functioneren de gezondheid en veiligheid van personen of eigendom in gevaar brengt
  *markttoezichtautoriteit: de nationale autoriteit die de activiteiten verricht en maatregelen neemt als bedoeld in Verordening (EU) 2019/1020
  *gemachtigde: een natuurlijke of rechtspersoon die zich bevindt of gevestigd is in de Unie die een schriftelijke machtiging heeft gekregen en aanvaard van een aanbieder van een AI-systeem of een AI-model voor algemene doeleinden om namens die aanbieder de verplichtingen en procedures van deze verordening respectievelijk na te komen en uit te voeren;
  *CE-markering: Een markering waarmee een aanbieder aangeeft dat een AI-systeem in overeenstemming is met de voorschriften van hoofdstuk III, afdeling 2, en andere toepasselijke harmonisatiewetgeving van de Unie, die in het aanbrengen ervan voorzien
  *distributeur: Een andere natuurlijke persoon of rechtspersoon in de toeleveringsketen dan de aanbieder of de importeur, die een AI-systeem in de Unie op de markt aanbiedt
  *importeur: Een natuurlijke of rechtspersoon die zich bevindt of gevestigd is in de Unie die een AI-systeem in de handel brengt dat de naam of merknaam van een in een derde land gevestigde natuurlijke of rechtspersoon draagt
  *gevoelige operationele gegevens: operationele gegevens met betrekking tot activiteiten op het gebied van preventie, opsporing, onderzoek of vervolging van strafbare feiten waarvan de openbaarmaking de integriteit van strafprocedures in het gedrang zou kunnen brengen
  *deepfake: door AI gegenereerd of gemanipuleerd beeld-, audio- of videomateriaal dat een gelijkenis vertoont met bestaande personen, voorwerpen, plaatsen, entiteiten of gebeurtenissen, en door een persoon ten onrechte voor authentiek of waarheidsgetrouw zou worden aangezien
  *capaciteiten met een grote impact: capaciteiten die overeenkomen met of groter zijn dan de capaciteiten die worden opgetekend bij de meest geavanceerde AI-modellen voor algemene doeleinden.
  *testen onder reële omstandigheden: het tijdelijk testen van een AI-systeem voor zijn beoogde doel onder reële omstandigheden buiten een laboratorium of anderszins gesimuleerde omgeving teneinde betrouwbare en robuuste gegevens te verkrijgen, en te beoordelen en te verifiëren of het AI-systeem overeenstemt met de voorschriften van de AI-verordening en het wordt niet aangemerkt als het in de handel brengen of in gebruik stellen van het AI-systeem in de zin van de AI-verordening, mits aan alle in artikel 57 of 60 vastgestelde voorwaarden is voldaan
  *geïnformeerde toestemming: de vrijelijk gegeven, specifieke, ondubbelzinnige en vrijwillige uiting door een proefpersoon van zijn of haar bereidheid deel te nemen aan een bepaalde test onder reële omstandigheden, na geïnformeerd te zijn over alle aspecten van de test die van belang zijn voor zijn of haar beslissing om deel te nemen
