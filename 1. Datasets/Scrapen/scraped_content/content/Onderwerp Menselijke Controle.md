---
title: Menselijke controle over algoritmes - Algoritmekader 2.2
url: https://minbzk.github.io/Algoritmekader/onderwerpen/menselijke-controle/
scraped_at: 2025-06-12T10:33:45.355894
---

# Menselijke controle over algoritmes - Algoritmekader 2.2

Source: https://minbzk.github.io/Algoritmekader/onderwerpen/menselijke-controle/

---

[ ![Home Algoritmekader](../../assets/logo.svg) ](../.. "Algoritmekader 2.2") Algoritmekader 2.2

[ GitHub  ](https://github.com/MinBZK/Algoritmekader "Ga naar repository")

  * [ Soorten algoritmes en AI  ](../../soorten-algoritmes-en-ai/)
  * Onderwerpen  Onderwerpen
    * [ Onderwerpen  ](../)

Onderwerpen
      * [ Discriminerende effecten en ander ongewenst onderscheid bij het gebruik van algoritmes  ](../bias-en-non-discriminatie/)
      * [ Verantwoord datagebruik  ](../data/)
      * [ Duurzaam werken met algoritmes  ](../duurzaamheid/)
      * [ Grondrechten beschermen in algoritmes  ](../fundamentele-rechten/)
      * [ Governance van algoritmes binnen je organisatie  ](../governance/)
      * Menselijke controle over algoritmes  [ Menselijke controle over algoritmes  ](./) Inhoudsopgave
        * Wat is menselijke controle?
        * Belang van menselijke controle
          * Ontwerp
          * Gebruik
          * Mensen
        * Aanpak menselijke controle
          * Feedback
        * Vereisten
        * Aanbevolen maatregelen
        * Hulpmiddelen
        * Help ons deze pagina te verbeteren
      * [ Privacy en persoonsgegevens beschermen in algoritmes  ](../privacy-en-gegevensbescherming/)
      * [ Inkoop van verantwoorde algoritmes  ](../publieke-inkoop/)
      * [ Technische robuustheid en veiligheid  ](../technische-robuustheid-en-veiligheid/)
      * [ Transparant zijn over algoritmes  ](../transparantie/)
  * [ Levenscyclus  ](../../levenscyclus/)
  * [ Rollen  ](../../rollen/)
  * [ Voldoen aan wetten en regels  ](../../voldoen-aan-wetten-en-regels/)

Inhoudsopgave

  * Wat is menselijke controle?
  * Belang van menselijke controle
    * Ontwerp
    * Gebruik
    * Mensen
  * Aanpak menselijke controle
    * Feedback
  * Vereisten
  * Aanbevolen maatregelen
  * Hulpmiddelen
  * Help ons deze pagina te verbeteren

  1. [ Onderwerpen  ](../)
  2. [ Onderwerpen  ](../)

# Menselijke controle over algoritmes

Algoritmes van de overheid moeten onder controle blijven van mensen. Presteert het algoritme niet goed, dan moet een mens dit kunnen aanpassen of stoppen.

## Wat is menselijke controle?

Menselijke controle over een algoritme of AI-systeem betekent dat mensen invloed hebben op de uitkomsten. Mensen moeten het ontwerp van het algoritme kunnen aanpassen. En mensen moeten het algoritme kunnen stoppen. Zo kun je op tijd ingrijpen als er iets fout gaat.

## Belang van menselijke controle

Algoritmes kunnen schade veroorzaken in de maatschappij. Gebruik je een algoritme voor een publieke taak, dan moet je dit continu op een of andere manier controleren.

### Ontwerp

Tijdens het ontwerp van een algoritme of AI-systeem controleer je bijvoorbeeld of het algoritme op de juiste manier ‘getraind’ wordt. Maakt het bijvoorbeeld gebruik van een goede dataset, zonder bias, die representatief is voor de samenleving? En je controleert of het algoritme bepaalde groepen niet benadeelt.

Voordat je een algoritme gaat gebruiken, is het belangrijk om [het doel te bepalen](../../voldoen-aan-wetten-en-regels/maatregelen/1-pba-02-formuleren-doelstelling/).

### Gebruik

Tijdens het gebruik van een algoritme is menselijke controle belangrijk omdat de werking verandert in de loop der tijd:

  * Situaties kunnen veranderen. Het algoritme kan daarvan niet op de hoogte zijn. Een routeplanner kent bijvoorbeeld niet alle werkzaamheden of veranderingen aan de wegen.
  * AI-systemen leren soms nog bij. En soms is het niet duidelijk op welke data de uitkomsten gebaseerd zijn. Een beeldherkenningssysteem herkent bijvoorbeeld honden op foto’s op basis van de achtergrond in plaats van de hond zelf.
  * Nieuwe mogelijkheden ontstaan door technologische ontwikkelingen. Zo maken leerlingen en studenten massaal gebruik van large language modellen (LLM’s) zoals ChatGPT.

### Mensen

Er is maatschappelijke consensus dat alleen natuurlijke personen in staat zijn om een goede (ethische) afweging te maken over wanneer en welke controle nodig is. Menselijke controle kan je dus niet automatiseren. Mensen mogen zich hierbij wel laten helpen door computers of andere technologie.

## Aanpak menselijke controle

Je kunt op verschillende manieren controle houden over de prestaties van een algoritme:

  * Technische controle: Controle uitoefenen op het algoritme zelf. Je bepaalt bijvoorbeeld dat een AI-systeem alleen mag 'bijleren’ wanneer de data voldoet aan bepaalde voorwaarden voor sociale representativiteit.
  * Contextuele controle: Controle van de omgeving van het algoritme. Je verbiedt bijvoorbeeld dat je organisatie het algoritme gebruikt in situaties met een hoog risico op schade.
  * Controle door kennis: Je probeert de werking en risico’s van je algoritmes zo goed mogelijk te begrijpen. Gaat het om een AI-systeem, dan heb je ook [voldoende kennis over AI](../../voldoen-aan-wetten-en-regels/vereisten/aia-01-ai-geletterdheid/) nodig.

Wanneer en hoe je controle uitoefent, hangt af van het [soort algoritme en risico](../../soorten-algoritmes-en-ai/wat-is-een-algoritme/), de [levenscyclusfase](../../levenscyclus/) van je project en je [expertise](../../rollen/).

Bepaal in elk geval zo vroeg mogelijk wie in welke levenscyclusfase verantwoordelijk is voor menselijke controle. En [beschrijf dit in een RACI-matrix of VERI-matrix](../../voldoen-aan-wetten-en-regels/maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/). Want menselijke controle is nodig in verschillende fases, door verschillende mensen. Er is nooit 1 persoon verantwoordelijk voor de totale controle.

Tijdens het gebruik kun je menselijke controle op de volgende manieren uitoefenen:

  * _Human in the loop_ : Een mens moet de acties starten van het algoritme. Het werkt niet uit zichzelf.
  * _Human on the loop_ : Mensen kunnen acties stoppen van het algoritme.
  * _Human above the loop_ : Mensen houden overzicht en kunnen ingrijpen bij strategische en ethische beslissingen.
  * _Human before the loop_ : Het algoritme interpreteert morele modellen die mensen vooraf bedenken. Deze oplossing is bedoeld voor volledig autonome algoritmes. Dit zijn algoritmes die zelf beslissingen moeten nemen, bijvoorbeeld door tijdsdruk.

### Feedback

Na het bepalen van de manier van controleren, bepaal je de manier waarop je feedback krijgt over het algoritme: Wat voor soort informatie moet bij wie terechtkomen? Aan wie moet een gebruiker bijvoorbeeld rapporteren dat het AI-systeem niet meer goed werkt?

## Vereisten

id| Vereisten
---|---
[aia-01](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-01-ai-geletterdheid/index.html)| [Personeel en gebruikers zijn voldoende AI-geletterd](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-01-ai-geletterdheid/index.html)
[aia-09](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-09-menselijk-toezicht/index.html)| [Hoog-risico-AI-systemen staan onder menselijk toezicht](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-09-menselijk-toezicht/index.html)
[aia-18](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-18-corrigerende-maatregelen-voor-non-conforme-ai/index.html)| [Als een hoog-risico-AI-systeem niet voldoet aan de AI-verordening, grijpt de aanbieder in](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-18-corrigerende-maatregelen-voor-non-conforme-ai/index.html)
[aia-19](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-19-toegankelijkheidseisen/index.html)| [Hoog-risico-AI-systemen voldoen aan de toegankelijkheidseisen](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-19-toegankelijkheidseisen/index.html)
[aia-21](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-21-gebruiksverantwoordelijken-menselijk-toezicht/index.html)| [Menselijk toezicht van hoog-risico-AI-systemen wordt uitgevoerd door mensen met voldoende kennis en mogelijkheden](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-21-gebruiksverantwoordelijken-menselijk-toezicht/index.html)
[aia-22](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-22-gebruiksverantwoordelijken-monitoren-werking/index.html)| [De werking van hoog-risico-AI-systemen wordt gemonitord](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-22-gebruiksverantwoordelijken-monitoren-werking/index.html)
[aia-36](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-36-melding-inbreuk-op-ai-verordening/index.html)| [Klokkenluiders kunnen veilig melden dat een organisatie zich niet houdt aan de AI-verordening](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-36-melding-inbreuk-op-ai-verordening/index.html)

## Aanbevolen maatregelen

id| Maatregelen
---|---
[org-12](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-12-periodieke-evaluatie-kwaliteit/index.html)| [Controleer en verbeter regelmatig de kwaliteit van het algoritme](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-12-periodieke-evaluatie-kwaliteit/index.html)
[pba-03](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/index.html)| [Beschrijf waarom een algoritme het probleem moet oplossen](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/index.html)
[owk-02](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/4-owk-02-stopzetten-gebruik/index.html)| [Maak een noodplan voor het stoppen van het algoritme](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/4-owk-02-stopzetten-gebruik/index.html)
[imp-01](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-01-werkinstructies-gebruikers/index.html)| [Stel een werkinstructie op voor gebruikers](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-01-werkinstructies-gebruikers/index.html)
[imp-03](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-03-menselijke-tussenkomst/index.html)| [Richt de juiste menselijke controle in van het algoritme](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-03-menselijke-tussenkomst/index.html)
[imp-09](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-09-interventies-ux/index.html)| [Neem technische interventies op in de gebruikersinterface om verkeerd gebruik te voorkomen](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-09-interventies-ux/index.html)

## Hulpmiddelen
  *norm: een norm is een vrijwillige afspraak tussen partijen over een product, dienst of proces. Normen zijn geen wetten, maar ’best practices’. Iedereen kan - op vrijwillige basis - hier zijn voordeel mee doen. In zakelijke overeenkomsten hebben normen een belangrijke functie. Ze bieden marktpartijen duidelijkheid over en vertrouwen in producten, diensten of organisaties en dagen de maatschappij uit te innoveren. NEN-normen worden ontwikkeld door inhoudsexperts en specialisten op het gebied van normontwikkeling.
  *aanbieder: Een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat een AI-systeem of een AI-model voor algemene doeleinden ontwikkelt of laat ontwikkelen en dat systeem of model in de handel brengt of het AI-systeem in gebruik stelt onder de eigen naam of merk, al dan niet tegen betaling.
  *AI-geletterdheid: vaardigheden, kennis en begrip die aanbieders, gebruiksverantwoordelijken en betrokken personen, rekening houdend met hun respectieve rechten en plichten in het kader van de de AI-verordening, in staat stellen met kennis van zaken AI-systemen in te zetten en zich bewuster te worden van de kansen en risico’s van AI en de mogelijke schade die zij kan veroorzaken
  *geharmoniseerde norm: Een Europese norm die op verzoek van de Commissie is vastgesteld met het oog op de toepassing van harmonisatiewetgeving van de Unie
  *conformiteitsbeoordeling: Het proces waarbij de naleving wordt aangetoond van de voorschriften van hoofdstuk III, afdeling 2 van de AI-Verordening in verband met een AI-systeem met een hoog risico
  *gebruiksverantwoordelijke: Een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat een AI-systeem onder eigen verantwoordelijkheid gebruikt, tenzij het AI-systeem wordt gebruikt in het kader van een persoonlijke niet- beroepsactiviteit.
  *AI-bureau: De taak van de Commissie waarbij zij bijdraagt aan de uitvoering van, de monitoring van en het toezicht op AI-systemen en AI-modellen voor algemene doeleinden, en AI-governance, als bepaald in het besluit van de Commissie van 24 januari 2024; verwijzingen in deze verordening naar het AI-bureau worden begrepen als verwijzingen naar de Commissie
  *proceseigenaar: De proceseigenaar is verantwoordelijk voor de kwaliteit van het proces en de vastlegging daarvan in een processchema
  *testdata: data die worden gebruikt voor het verrichten van een onafhankelijke evaluatie van het AI-systeem om de verwachte prestaties van dat systeem te bevestigen voordat het in de handel wordt gebracht of in gebruik wordt gesteld
  *verwerker: Een .. rechtspersoon, een overheidsinstantie, een dienst of een ander orgaan die/dat ten behoeve van de verwerkingsverantwoordelijke persoonsgegevens verwerkt.
  *trainingsdata: data die worden gebruikt voor het trainen van een AI-systeem door de leerbare parameters hiervan aan te passen
  *AI-model voor algemene doeleinden: Een AI-model, ook wanneer het is getraind met een grote hoeveelheid data met behulp van self-supervision op grote schaal, dat een aanzienlijk algemeen karakter vertoont en in staat is op competente wijze een breed scala aan verschillende taken uit te voeren, ongeacht de wijze waarop het model in de handel wordt gebracht, en dat kan worden geïntegreerd in een verscheidenheid aan systemen verder in de AI-waardeketen of toepassingen verder in de AI-waardeketen, met uitzondering van AI-modellen die worden gebruikt voor onderzoek, ontwikkeling of prototypingactiviteiten alvorens zij in de handel worden gebracht.
  *AI-systeem voor algemene doeleinden: Een AI-systeem dat is gebaseerd op een AI- model voor algemene doeleinden en dat verschillende doeleinden kan dienen, zowel voor direct gebruik als voor integratie in andere AI-systemen
  *importeur: Een natuurlijke of rechtspersoon die zich bevindt of gevestigd is in de Unie die een AI-systeem in de handel brengt dat de naam of merknaam van een in een derde land gevestigde natuurlijke of rechtspersoon draagt
  *distributeur: Een andere natuurlijke persoon of rechtspersoon in de toeleveringsketen dan de aanbieder of de importeur, die een AI-systeem in de Unie op de markt aanbiedt
  *gemachtigde: een natuurlijke of rechtspersoon die zich bevindt of gevestigd is in de Unie die een schriftelijke machtiging heeft gekregen en aanvaard van een aanbieder van een AI-systeem of een AI-model voor algemene doeleinden om namens die aanbieder de verplichtingen en procedures van deze verordening respectievelijk na te komen en uit te voeren;
  *discriminatiegrond: Beschermde persoonskenmerken op basis waarvan het maken van onderscheid tussen personen verboden is. Bijvoorbeeld: ras, nationaliteit, religie, geslacht, seksuele gerichtheid, handicap of chronische ziekte.
  *indirect onderscheid: Indien een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een bepaalde godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, nationaliteit, hetero- of homoseksuele gerichtheid of burgerlijke staat in vergelijking met andere personen bijzonder treft.
  *objectieve rechtvaardiging: Van een objectieve rechtvaardiging voor onderscheid is sprake wanneer onderscheid een legitiem doel nastreeft en er een redelijke relatie van evenredigheid bestaat tussen het gemaakte onderscheid en het nagestreefde doel.
