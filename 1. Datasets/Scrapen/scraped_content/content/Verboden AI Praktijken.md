---
title: Verboden AI mag niet worden gebruikt - Algoritmekader 2.2
url: https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-00-verboden-AI-praktijken/index.html
scraped_at: 2025-06-11T13:47:12.483092
---

# Verboden AI mag niet worden gebruikt - Algoritmekader 2.2

Source: https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/vereisten/aia-00-verboden-AI-praktijken/index.html

---

[ ![Home Algoritmekader](../../../assets/logo.svg) ](../../.. "Algoritmekader 2.2") Algoritmekader 2.2

[ GitHub  ](https://github.com/MinBZK/Algoritmekader "Ga naar repository")

  * [ Soorten algoritmes en AI  ](../../../soorten-algoritmes-en-ai/)
  * [ Onderwerpen  ](../../../onderwerpen/)
  * [ Levenscyclus  ](../../../levenscyclus/)
  * [ Rollen  ](../../../rollen/)
  * [ Voldoen aan wetten en regels  ](../../)

Inhoudsopgave

  * Vereiste
  * Toelichting
  * Bronnen
  * Van toepassing op
  * Risico
  * Maatregelen

  1. [ Voldoen aan wetten en regels  ](../../)
  2. [ Vereisten  ](../)

# Verboden AI mag niet worden gebruikt

[]( "Vereiste ID")aia-00[](../../../levenscyclus/ "Levencyclus")[Organisatieverantwoordelijkheden](../../../levenscyclus/organisatieverantwoordelijkheden/)[](../../../levenscyclus/ "Levencyclus")[Probleemanalyse](../../../levenscyclus/probleemanalyse/)[](../../../rollen/ "Rollen")[Projectleider](../../../rollen/projectleider/)[](../../../onderwerpen/ "Onderwerp")[Governance](../../../onderwerpen/governance/)

## Vereiste

Verboden AI-systemen mogen niet worden gebruikt.

## Toelichting

Afgezien van de vele nuttige toepassingen van AI kan zij ook worden misbruikt en nieuwe en krachtige instrumenten voor manipulatie, uitbuiting en sociale controle opleveren. Dergelijke praktijken zijn bijzonder schadelijk en abusief en moeten worden verboden omdat zij in strijd zijn met de waarden van de Unie, namelijk eerbied voor de menselijke waardigheid, vrijheid, gelijkheid, democratie en de rechtsstaat, en met de grondrechten van de Unie die zijn vastgelegd in het Handvest, waaronder het recht op non-discriminatie, gegevensbescherming en privacy, en de rechten van het kind.

In de volgende gevallen gaat het om een verboden toepassing op grond van de AI-verordening:

  * gebruik kan gaan maken van subliminale technieken om mensen onbewust of bewust kunnen manipuleren, waardoor ze beslissingen nemen die ze anders niet zouden hebben genomen?
  * gebruik kan gaan maken van kwetsbaarheden van individuen of specifieke groepen, zoals leeftijd, handicaps of sociale/economische omstandigheden, om het gedrag van die personen aanzienlijk te verstoren, wat kan leiden tot aanzienlijke schade bij henzelf of anderen?
  * gebruikt kan worden om natuurlijke personen of groepen gedurende een periode te evalueren of te classificeren op basis van hun sociale gedrag of afgeleide persoonlijke kenmerken?
  * gebruikt kan worden voor risicobeoordelingen van natuurlijke personen om het risico op crimineel gedrag te voorspellen, gebaseerd op profilering of persoonlijkheidskenmerken? (Dit geldt niet voor AI-systemen die worden gebruikt om menselijke beoordelingen te ondersteunen, gebaseerd op objectieve en verifieerbare feiten die rechtstreeks verband houden met criminele activiteiten)
  * gebruikt kan worden om databanken voor gezichtsherkenning aan te leggen of aan te vullen door willekeurige gezichtsafbeeldingen van internet of CCTV-beelden te scrapen?
  * gebruikt kan worden om emoties van een persoon op de werkplek of in het onderwijs af te leiden? (Dit is niet van toepassing als het gebruik van het AI-systeem is bedoeld voor medische- of veiligheidsdoeleinden)
  * gebruikt kan worden om natuurlijke personen individueel in categorieën in te delen op basis van biometrische gegevens om ras, politieke opvattingen, lidmaatschap van een vakbond, religieuze of levensbeschouwelijke overtuigingen, seksleven of seksuele geaardheid af te leiden? (Dit verbod geldt niet voor het labelen of filteren van rechtmatig verkregen biometrische datasets, zoals afbeeldingen, op basis van biometrische gegevens, of voor categorisering van biometrische gegevens op het gebied van rechtshandhaving)
  * gebruikt kan worden als een biometrisch systeem in de publieke ruimte voor identificatie op afstand in real-time, met het oog op de rechtshandhaving?

Er zijn een tweetal uitzonderingen voor het inzetten van verbonden AI-systemen. Deze zijn:

  * Er is sprake van een rechtshandhavingsactiviteit i.v.m. een specifiek misdrijf (terrorisme, mensenhandel, seksuele uitbuiting van kinderen en materiaal over seksueel misbruik van kinderen, illegale handel in verdovende middelen en psychotrope stoffen, illegale handel in wapens, munitie en explosieven, moord, zware mishandeling, illegale handel in menselijke organen en weefsels, illegale handel in nucleaire en radioactieve stoffen, ontvoering, wederrechtelijke vrijheidsberoving en gijzeling, misdrijven die onder de rechtsmacht van het Internationaal Strafhof vallen, kaping van vliegtuigen/schepen, verkrachting, milieucriminaliteit, georganiseerde of gewapende diefstal, sabotage, deelneming aan een criminele organisatie die betrokken is bij een of meer van de bovengenoemde misdrijven).
  * Er is sprake van gerichte opsporing van specifieke slachtoffers, ontvoering, mensenhandel en seksuele uitbuiting van mensen, vermiste personen; of het voorkomen van bedreigingen voor het leven of de fysieke veiligheid van personen of het reageren op de huidige of voorzienbare dreiging van een terreuraanslag.

Bepaal in een vroege fase en bij het [onderbouwen van het gebruik van een AI-systeem](../../maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/) of de beoogde toepassing is toegestaan.

Richtsnoeren over verboden AI-praktijken vanuit de Europese Commissie

De Europese Commissie heeft [richtsnoeren inzake verboden praktijken op het gebied van AI](https://digital-strategy.ec.europa.eu/en/library/commission-publishes-guidelines-prohibited-artificial-intelligence-ai-practices-defined-ai-act), zoals gedefinieerd door de AI-verordening, gepubliceerd. Deze richtlijnen geven een overzicht van AI-praktijken die onacceptabel worden geacht vanwege hun mogelijke risico's voor Europese waarden en grondrechten.

## Bronnen

[Artikel 5 Verordening Artificiële Intelligentie](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1).

[Overweging 29 - 44 AI-Verordening](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2799-1-1).

[Handreiking identificatie verboden AI-systemen (Powerpoint-bestand)](https://github.com/user-attachments/files/18179666/Handreiking_Uitvraag_VBSystemen.pptx)

## Van toepassing op

Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de [beslishulp](https://ai-act-decisiontree.apps.digilab.network) voor hulp bij wat er in jouw situatie van toepassing is.

[](../../../soorten-algoritmes-en-ai/wat-is-een-algoritme/ "Soort toepassing")[AI-systeem](../../ai-verordening/#ai-systeem)[](../../../soorten-algoritmes-en-ai/wat-is-een-algoritme/ "Soort toepassing")[AI-systeem voor algemene doeleinden](../../ai-verordening/#ai-model-voor-algemene-doeleinden)[](../../../soorten-algoritmes-en-ai/wat-is-een-algoritme/ "Soort toepassing")[AI-model voor algemene doeleinden](../../ai-verordening/#ai-model-voor-algemene-doeleinden)[](../../ai-verordening/#risicogroepen "Risicogroep")[Verboden AI](../../../soorten-algoritmes-en-ai/risico-van-ai-systemen/#verboden-ai)[](../../ai-verordening/#rollen-uit-de-ai-verordening "Rol AI-verordening")[Aanbieder](../../ai-verordening/#aanbieder)[](../../ai-verordening/#rollen-uit-de-ai-verordening "Rol AI-verordening")[Gebruiksverantwoordelijke](../../ai-verordening/#gebruiksverantwoordelijke)[](../../ai-verordening/#rollen-uit-de-ai-verordening "Rol AI-verordening")[Importeur](../../ai-verordening/#andere-rollen)[](../../ai-verordening/#rollen-uit-de-ai-verordening "Rol AI-verordening")[Distributeur](../../ai-verordening/#andere-rollen)[](../../ai-verordening/#ai-model-voor-algemene-doeleinden "Systeemrisico AI-verordening")[Systeemrisico](../../ai-verordening/#ai-model-voor-algemene-doeleinden)[](../../ai-verordening/#ai-model-voor-algemene-doeleinden "Systeemrisico AI-verordening")[Geen systeemrisico](../../ai-verordening/#ai-model-voor-algemene-doeleinden)[](../../../soorten-algoritmes-en-ai/risico-van-ai-systemen/#risico-op-misleiding "Transparantieverplichting AI-verordening")[Geen transparantieverplichting](../../../soorten-algoritmes-en-ai/risico-van-ai-systemen/#risico-op-misleiding)[](../../../soorten-algoritmes-en-ai/risico-van-ai-systemen/#risico-op-misleiding "Transparantieverplichting AI-verordening")[Transparantieverplichting](../../../soorten-algoritmes-en-ai/risico-van-ai-systemen/#risico-op-misleiding)

## Risico

Er ontstaat een onrechtmatige situatie voor een organisatie als deze AI inzet, die verboden is.

## Maatregelen

id| Maatregelen
---|---
[org-00](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-00-inventariseren-algoritmes/index.html)| [Inventariseer de algoritmes die binnen jouw organisatie worden gebruikt en houd dit overzicht actueel](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-00-inventariseren-algoritmes/index.html)
[pba-03](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/index.html)| [Beschrijf waarom een algoritme het probleem moet oplossen](https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/index.html)
14 februari 2025 16 december 2024
  *AI-modellen voor algemene doeleinden: Een AI-model, ook wanneer het is getraind met een grote hoeveelheid data met behulp van self-supervision op grote schaal, dat een aanzienlijk algemeen karakter vertoont en in staat is op competente wijze een breed scala aan verschillende taken uit te voeren, ongeacht de wijze waarop het model in de handel wordt gebracht, en dat kan worden geïntegreerd in een verscheidenheid aan systemen verder in de AI-waardeketen of toepassingen verder in de AI-waardeketen, met uitzondering van AI-modellen die worden gebruikt voor onderzoek, ontwikkeling of prototypingactiviteiten alvorens zij in de handel worden gebracht.
  *AI-geletterdheid: vaardigheden, kennis en begrip die aanbieders, gebruiksverantwoordelijken en betrokken personen, rekening houdend met hun respectieve rechten en plichten in het kader van de de AI-verordening, in staat stellen met kennis van zaken AI-systemen in te zetten en zich bewuster te worden van de kansen en risico’s van AI en de mogelijke schade die zij kan veroorzaken
  *AI-model voor algemene doeleinden: Een AI-model, ook wanneer het is getraind met een grote hoeveelheid data met behulp van self-supervision op grote schaal, dat een aanzienlijk algemeen karakter vertoont en in staat is op competente wijze een breed scala aan verschillende taken uit te voeren, ongeacht de wijze waarop het model in de handel wordt gebracht, en dat kan worden geïntegreerd in een verscheidenheid aan systemen verder in de AI-waardeketen of toepassingen verder in de AI-waardeketen, met uitzondering van AI-modellen die worden gebruikt voor onderzoek, ontwikkeling of prototypingactiviteiten alvorens zij in de handel worden gebracht.
  *biometrische gegevens: persoonsgegevens die het resultaat zijn van een specifieke technische verwerking met betrekking tot de fysieke, fysiologische of gedragsgerelateerde kenmerken van een natuurlijk persoon, zoals gezichtsafbeeldingen of vingerafdrukgegevens
  *AI-systeem voor algemene doeleinden: Een AI-systeem dat is gebaseerd op een AI- model voor algemene doeleinden en dat verschillende doeleinden kan dienen, zowel voor direct gebruik als voor integratie in andere AI-systemen
  *systeemrisico: een risico dat specifiek is voor de capaciteiten met een grote impact van AI-modellen voor algemene doeleinden, die aanzienlijke gevolgen hebben voor de markt van de Unie vanwege hun bereik, of vanwege feitelijke of redelijkerwijs te voorziene negatieve gevolgen voor de gezondheid, de veiligheid, de openbare veiligheid, de grondrechten of de samenleving als geheel, en dat op grote schaal in de hele waardeketen kan worden verspreid
